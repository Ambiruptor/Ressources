---------- Xuan : finding an existing corpus -------------

http://www.nltk.org/nltk_data/

(1) The Gutenburg Corpus : 25000 free electric books
http://www.gutenberg.org/
Use nltk corpus gutenburg files

(2) Web and chat text
http://faculty.nps.edu/cmartell/NPSChat.htm

(3) The brown corpus
http://www.hit.uib.no/icame/brown/bcm.html

(4) Reuters corpus
http://kdd.ics.uci.edu/databases/reuters21578/reuters21578.html

-------------- Pierre : features extraction ---------------

(1) Part of speech of the neighbours in the next. ( in [0, 9])
-----------_______W_______-----------------
           <--l--> <--l-->

(2) Most common words linked. (ex "factory", in [0, 1])

(3) Group of words ?

(4) Corpus like brown : in which category is the text ?

----------- Victor & Simon : creating a corpus -------------

We can create Heuristic on existing texts.
But the learning part can't be better than the heuristic part.

------------- Eugenia : Using Wikipedia ------------------

http://www.coli.uni-saarland.de/courses/comsem-12/material/WSD_weiqiu.pdf

------------ Wikipedia as a training corpus --------------

Sense = wikipedia article.

For each link of wikipedia
  We create one vector of sense the url
  
------------------------- Pierre -----------------------

One model for each ambiguous word.

Corpus = all pages that contains a link to an ambiguous word

